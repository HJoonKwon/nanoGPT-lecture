{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b819498a-6bc8-4f3e-8f34-8e04400487d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We always start with a dataset to train on. Let's download the tiny shakespeare dataset\n",
    "# !wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "280a1d0b-9488-4819-8b75-efe95d229ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read it in to inspect it\n",
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cbc5da4-9484-493b-bc7b-34a7ae99247e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of the text file = 1115394\n"
     ]
    }
   ],
   "source": [
    "print(f\"length of the text file = {len(text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4886aaca-db29-4aa0-895b-7d41f1a8f1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "648ba44e-39e8-4331-9617-5507e6e39858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e37ea57-2dd9-4434-a95d-c142d16ce99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = {s:i for i, s in enumerate(chars)}\n",
    "itos = {i:s for s, i in stoi.items()} \n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: ''.join([itos[i] for i in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb13f1ad-b284-4f17-8c53-fd5f578f239a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 47, 1, 58, 46, 43, 56, 43]\n",
      "hi there\n"
     ]
    }
   ],
   "source": [
    "print(encode('hi there'))\n",
    "print(decode(encode('hi there')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f64ed2f-8bb4-40c8-b593-cb17c1a1858c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f77ba381-5d75-4e7d-839a-8647ff75099f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(len(data) * 0.9) \n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4a0d62b-2426-4489-b309-0efd24af96a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8 \n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d47fec53-59fe-49ff-98fa-754e98a263ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: tensor([18]) ---> target: 47\n",
      "input: tensor([18, 47]) ---> target: 56\n",
      "input: tensor([18, 47, 56]) ---> target: 57\n",
      "input: tensor([18, 47, 56, 57]) ---> target: 58\n",
      "input: tensor([18, 47, 56, 57, 58]) ---> target: 1\n",
      "input: tensor([18, 47, 56, 57, 58,  1]) ---> target: 15\n",
      "input: tensor([18, 47, 56, 57, 58,  1, 15]) ---> target: 47\n",
      "input: tensor([18, 47, 56, 57, 58,  1, 15, 47]) ---> target: 58\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"input: {context} ---> target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07d1649f-e9df-4613-a532-eae089f8a10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs\n",
      "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
      "shape = torch.Size([4, 8])\n",
      "outputs\n",
      "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
      "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
      "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
      "        [17, 27, 10,  0, 21,  1, 54, 39]])\n",
      "shape = torch.Size([4, 8])\n",
      "----------------------------\n",
      "inputs: tensor([24]) --> target: 43\n",
      "inputs: tensor([24, 43]) --> target: 58\n",
      "inputs: tensor([24, 43, 58]) --> target: 5\n",
      "inputs: tensor([24, 43, 58,  5]) --> target: 57\n",
      "inputs: tensor([24, 43, 58,  5, 57]) --> target: 1\n",
      "inputs: tensor([24, 43, 58,  5, 57,  1]) --> target: 46\n",
      "inputs: tensor([24, 43, 58,  5, 57,  1, 46]) --> target: 43\n",
      "inputs: tensor([24, 43, 58,  5, 57,  1, 46, 43]) --> target: 39\n",
      "inputs: tensor([44]) --> target: 53\n",
      "inputs: tensor([44, 53]) --> target: 56\n",
      "inputs: tensor([44, 53, 56]) --> target: 1\n",
      "inputs: tensor([44, 53, 56,  1]) --> target: 58\n",
      "inputs: tensor([44, 53, 56,  1, 58]) --> target: 46\n",
      "inputs: tensor([44, 53, 56,  1, 58, 46]) --> target: 39\n",
      "inputs: tensor([44, 53, 56,  1, 58, 46, 39]) --> target: 58\n",
      "inputs: tensor([44, 53, 56,  1, 58, 46, 39, 58]) --> target: 1\n",
      "inputs: tensor([52]) --> target: 58\n",
      "inputs: tensor([52, 58]) --> target: 1\n",
      "inputs: tensor([52, 58,  1]) --> target: 58\n",
      "inputs: tensor([52, 58,  1, 58]) --> target: 46\n",
      "inputs: tensor([52, 58,  1, 58, 46]) --> target: 39\n",
      "inputs: tensor([52, 58,  1, 58, 46, 39]) --> target: 58\n",
      "inputs: tensor([52, 58,  1, 58, 46, 39, 58]) --> target: 1\n",
      "inputs: tensor([52, 58,  1, 58, 46, 39, 58,  1]) --> target: 46\n",
      "inputs: tensor([25]) --> target: 17\n",
      "inputs: tensor([25, 17]) --> target: 27\n",
      "inputs: tensor([25, 17, 27]) --> target: 10\n",
      "inputs: tensor([25, 17, 27, 10]) --> target: 0\n",
      "inputs: tensor([25, 17, 27, 10,  0]) --> target: 21\n",
      "inputs: tensor([25, 17, 27, 10,  0, 21]) --> target: 1\n",
      "inputs: tensor([25, 17, 27, 10,  0, 21,  1]) --> target: 54\n",
      "inputs: tensor([25, 17, 27, 10,  0, 21,  1, 54]) --> target: 39\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4 # how many examples to put into the model in parellel \n",
    "block_size = 8 # the maximum context length to predict the next token  \n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split=='train' else val_data \n",
    "    ix = torch.randint(len(data) - block_size, (batch_size, ))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y \n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print('inputs')\n",
    "print(xb)\n",
    "print(f'shape = {xb.shape}')\n",
    "print('outputs')\n",
    "print(yb)\n",
    "print(f'shape = {yb.shape}')\n",
    "print('----------------------------')\n",
    "\n",
    "for bi in range(batch_size):\n",
    "    for ti in range(block_size):\n",
    "        context = xb[bi, :ti+1]\n",
    "        target = yb[bi, ti]\n",
    "        print(f\"inputs: {context} --> target: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ce1ad06-1365-470e-acb6-f33890369682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1081275,  241627,  748567,  905830])\n",
      "tensor([[53, 59, 56,  0, 41, 39, 40, 47],\n",
      "        [63, 53, 59,  1, 39, 50, 50,  6],\n",
      "        [ 0, 24, 17, 27, 26, 32, 17, 31],\n",
      "        [ 1, 39, 52, 42,  1, 59, 52, 56]])\n",
      "tensor([[59, 56,  0, 41, 39, 40, 47, 52],\n",
      "        [53, 59,  1, 39, 50, 50,  6,  1],\n",
      "        [24, 17, 27, 26, 32, 17, 31, 10],\n",
      "        [39, 52, 42,  1, 59, 52, 56, 59]])\n"
     ]
    }
   ],
   "source": [
    "ix = torch.randint(len(data) - block_size, (batch_size, ))\n",
    "x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "print(ix)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "798a136d-a1ff-4d52-9b47-672266e5596a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 65])\n",
      "tensor(4.4547, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "Yr.YjvmHFQqBWq$?lP$PbdNM.\n",
      "IT:aT:XAFhQMX:WMlcvTqeVtA:$?whM&KAXBk$JBh,zo!-fHP?$quhdMrn yNx-Vi3rXf?:Hxw\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "torch.manual_seed(2024)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None): # targets = (B, T)\n",
    "        logits = self.token_embedding_table(idx) # idx = (B, T)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None \n",
    "        else:\n",
    "            B, T, C = logits.shape \n",
    "            logits = logits.view(B*T, C) \n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        return logits, loss  \n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for i in range(max_new_tokens):\n",
    "            logits, loss = self(idx)\n",
    "            logits = logits[:, -1, :] # (B, C) \n",
    "            probs = F.softmax(logits, -1) # (B, C)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx  \n",
    "\n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "\n",
    "print(decode(m.generate(idx=torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3fe2b7fc-4df3-4661-b3ea-0bb3be646ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3fe8342-cf32-483f-aee3-981312f730de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4225\n"
     ]
    }
   ],
   "source": [
    "print(sum([p.nelement() for p in m.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94e23c2b-aff3-40f4-867c-d7bce1329afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.542457342147827\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32 \n",
    "\n",
    "for steps in range(10000):\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step() \n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dea542d1-3a2c-402c-b56f-23965f8e60ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Fle aimak, chiderorg, sowerdsex, aner sstt win wime curve,\n",
      "ARDY:\n",
      "T:\n",
      "\n",
      "THEETas Verir oey oo awi.\n",
      "Morarei's ste the y sustea ntulf n Mar rpuctangacer out t'd bry,\n",
      "\n",
      "Therd a beacang r GoR:\n",
      "\n",
      "Jus dowin IZETy ILowis on anine, tthieprl;\n",
      "DUSLAs ing.\n",
      "F hethofer se bore anthi othe\n",
      "Aghou f gase Tifanuamat'ge hel pouea averentig cere, yeban noubr? ted rethedr;\n",
      "S:\n",
      "TORDELI f h teen,RD foour wne atth ll mas k-3Les ath d ndsst, f leplot. lanotele chele ory s teran's be se to y hiathis Thoree,\n",
      "\n",
      "\n",
      "Gomf bubanom ay f\n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(idx=torch.zeros((1, 1), dtype=torch.long), max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bb1ee38e-254c-431a-9d4d-a8557a643895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "b = tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "c = tensor([[2.0000, 7.0000],\n",
      "        [4.0000, 5.5000],\n",
      "        [4.6667, 5.3333]])\n"
     ]
    }
   ],
   "source": [
    "# aggregated weighted sum (toy example)\n",
    "# b = weight \n",
    "# a = data \n",
    "# c = weighted sum \n",
    "torch.manual_seed(42)\n",
    "a = torch.tril(torch.ones(3,3))\n",
    "a /= a.sum(1, keepdim=True)\n",
    "b = torch.randint(0, 10, (3, 2)).float()\n",
    "c = a @ b\n",
    "print(f'a = {a}') # (T, T)\n",
    "print(f'b = {b}') # (T, C)\n",
    "print(f'c = {c}') # (T, C) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fef5a21d-4bbf-4316-89e1-de6fca34b49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# toy example with Batch dimension with different approach \n",
    "B, T, C = 4, 8, 2\n",
    "x = torch.randn((B, T, C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f0daab54-12a3-4949-9876-7d773cc1db1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.5 µs ± 33.2 µs per loop (mean ± std. dev. of 10 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 10 -n 100\n",
    "# 1) first approach. Use tril and sum/div. \n",
    "weight = torch.tril(torch.ones(T, T))\n",
    "weight /= weight.sum(1, keepdim=True)\n",
    "xbow = weight @ x # (T, T) @ (B, T, C) = (B, T, T) @ (B, T, C) = (B, T, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "98a2b6e6-8307-4f87-8900-2a3c6312f886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570 µs ± 16 µs per loop (mean ± std. dev. of 10 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 10 -n 100\n",
    "# 2) second approach. Use mean(). \n",
    "xbow2 = torch.zeros((B, T, C))\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b, :t+1] # (T, C)\n",
    "        xbow2[b, t] = torch.mean(xprev, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ab59cf74-e2ba-4952-931e-13de640eb13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 4.07 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "71.8 µs ± 47.7 µs per loop (mean ± std. dev. of 10 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 10 -n 100\n",
    "# 3) third approach. Use softmax(). \n",
    "weight = torch.tril(torch.ones(T, T))\n",
    "weight = weight.masked_fill(weight == 0, float('-inf'))\n",
    "weight = F.softmax(weight, -1)\n",
    "xbow3 = weight @ x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7ead8605-2c2b-4b21-9ec6-d00c9b46e556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All three approaches result in the same values \n",
    "torch.allclose(xbow, xbow2) and torch.allclose(xbow2, xbow3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8beb90da-3a94-4933-b9f7-a6b13528dd54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight shape =  torch.Size([4, 8, 8])\n",
      "torch.Size([4, 8, 16])\n"
     ]
    }
   ],
   "source": [
    "# Self Attention! \n",
    "B, T, C = 4, 8, 32 \n",
    "x = torch.randn((B, T, C))\n",
    "\n",
    "# single-head attention\n",
    "head_size = 16 \n",
    "query = nn.Linear(C, head_size, bias=False) \n",
    "key = nn.Linear(C, head_size, bias=False) \n",
    "\n",
    "q = query(x) # (B, T, H)\n",
    "k = key(x) # (B, T, H)\n",
    "\n",
    "weight = q @ k.transpose(-2, -1) # (B, T, H) @ (B, H, T) = (B, T, T) \n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "weight = weight.masked_fill(tril == 0, float('-inf')) # For auto-regressive GPT-like training! \n",
    "weight = F.softmax(weight, -1)\n",
    "print('weight shape = ', weight.shape)\n",
    "\n",
    "value = nn.Linear(C, head_size, bias=False) # head_size can be a different value here. \n",
    "v = value(x)\n",
    "out = weight @ v # (B, T, T) @ (B, T, H) = (B, T, H) \n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8fa4b5aa-afaf-4155-993c-172341348e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00],\n",
       "        [8.4499e-01, 1.5501e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00],\n",
       "        [3.1584e-03, 7.7195e-02, 9.1965e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00],\n",
       "        [2.6547e-01, 1.7364e-01, 4.4769e-01, 1.1320e-01, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00],\n",
       "        [2.6996e-01, 3.5359e-02, 2.0242e-01, 4.9041e-01, 1.8540e-03, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00],\n",
       "        [2.5932e-02, 7.9924e-01, 9.2701e-03, 2.3191e-02, 1.3992e-01, 2.4518e-03,\n",
       "         0.0000e+00, 0.0000e+00],\n",
       "        [1.5187e-02, 2.6657e-02, 7.2245e-01, 9.9532e-02, 3.9899e-02, 6.0522e-02,\n",
       "         3.5756e-02, 0.0000e+00],\n",
       "        [1.9527e-03, 8.4461e-03, 1.2466e-03, 1.1848e-03, 2.0492e-01, 4.1170e-04,\n",
       "         7.7931e-01, 2.5307e-03]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d57a83a-38fe-4cfd-b200-e91759fb0093",
   "metadata": {},
   "source": [
    "Notes:\n",
    "Attention is a communication mechanism. Can be seen as nodes in a directed graph looking at each other and aggregating information with a weighted sum from all nodes that point to them, with data-dependent weights.\n",
    "There is no notion of space. Attention simply acts over a set of vectors. This is why we need to positionally encode tokens.\n",
    "Each example across batch dimension is of course processed completely independently and never \"talk\" to each other\n",
    "In an \"encoder\" attention block just delete the single line that does masking with tril, allowing all tokens to communicate. This block here is called a \"decoder\" attention block because it has triangular masking, and is usually used in autoregressive settings, like language modeling.\n",
    "\"self-attention\" just means that the keys and values are produced from the same source as queries. In \"cross-attention\", the queries still get produced from x, but the keys and values come from some other, external source (e.g. an encoder module)\n",
    "\"Scaled\" attention additional divides wei by 1/sqrt(head_size). This makes it so when input Q,K are unit variance, wei will be unit variance too and Softmax will stay diffuse and not saturate too much. Illustration below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ac897df1-f5cc-41a3-9f34-18cbc1f5d8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0085)\n",
      "tensor(0.9305)\n",
      "tensor(1.0599)\n"
     ]
    }
   ],
   "source": [
    "# Scaled self-attention! \n",
    "q = torch.randn((B, T, head_size))\n",
    "k = torch.randn((B, T, head_size))\n",
    "weight = q @ k.transpose(-2, -1) * head_size ** -0.5 \n",
    "print(q.var())\n",
    "print(k.var())\n",
    "print(weight.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f66a430b-2aad-436a-970b-2277c7b5ac3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.7132e-02, 4.2467e-05, 8.5298e-04, 4.6571e-02, 9.3540e-01])\n",
      "tensor([4.2484e-18, 3.7835e-44, 3.9754e-31, 9.3576e-14, 1.0000e+00])\n"
     ]
    }
   ],
   "source": [
    "# Why unit variance? \n",
    "low_var = F.softmax(torch.tensor([1.0, -5.0, -2.0, 2.0, 5.0]), -1)\n",
    "high_var = F.softmax(torch.tensor([1.0, -5.0, -2.0, 2.0, 5.0]) * 10, -1)\n",
    "print(low_var)\n",
    "print(high_var) # too peaky --> converges to one-hot --> less meaningful training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4723a8c4-99b0-4b24-bf3f-89412fbb130b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
